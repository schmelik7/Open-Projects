{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### My first data pipeline project, I made the rookie mistake of overwriting most of my steps in the same file. I've recovered what I could just to have something on my github to help the reader see into my process taht led to the dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One of many attempts to clean CSV's\n",
    "\n",
    "import csv\n",
    "\n",
    "def reformat_csv(input_file, output_file):\n",
    "    with open(input_file, 'r', newline='', encoding='utf-8') as infile, \\\n",
    "         open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        \n",
    "        reader = csv.reader(infile, quotechar='\"', escapechar='\\\\', doublequote=True, skipinitialspace=True)\n",
    "        writer = csv.writer(outfile, quotechar='\"', quoting=csv.QUOTE_MINIMAL, escapechar='\\\\', lineterminator='\\n')\n",
    "        \n",
    "        current_row = []\n",
    "        line_number = 0\n",
    "        \n",
    "        for row in reader:\n",
    "            line_number += 1\n",
    "            if not row:  # Skip empty rows\n",
    "                continue\n",
    "                \n",
    "            if current_row:  # Continuing a multi-line field\n",
    "                current_row.extend(row)\n",
    "            else:\n",
    "                current_row = row\n",
    "            \n",
    "            # Check if the last field is properly closed (ends with a quote)\n",
    "            if current_row and current_row[-1].endswith('\"'):\n",
    "                writer.writerow(current_row)\n",
    "                print(f\"Written complete row at line {line_number}\")\n",
    "                current_row = []\n",
    "            else:\n",
    "                print(f\"Buffering row at line {line_number} - incomplete quote detected\")\n",
    "\n",
    "        if current_row:  # Handle any remaining rows\n",
    "            writer.writerow(current_row)\n",
    "            print(f\"Written final row at line {line_number}\")\n",
    "\n",
    "    print(f\"Reformatting complete. Check {output_file}.\")\n",
    "\n",
    "# Usage with explicit paths\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '/Users/sam/Documents/Academics/Data/Udemy Dash/edx_courses.csv'  # Update this path\n",
    "    output_file = '/Users/sam/Documents/Academics/Data/Udemy Dash/edx_courses_new.csv'  # Update this path\n",
    "    reformat_csv(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Querying through bigquery \n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "\n",
    "# Set the environment variable for authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/sam/Documents/Academics/Data/UdemyDash/planar-effect-452317-h6-597d463b43bb.json\"\n",
    "\n",
    "# Set up your BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Write your query (with corrected syntax)\n",
    "query = \"\"\" \n",
    "\n",
    "SELECT title, price, course_effort, n_enrolled, institution\n",
    "FROM `planar-effect-452317-h6.Udemy_Courses.udemy` \n",
    "WHERE subject == 'Computer Science'\n",
    "ORDER BY price DESC LIMIT 15\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a DataFrame\n",
    "df = client.query(query).to_dataframe()\n",
    "\n",
    "# Improve display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Display the result\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving cleaned queried tables to new csv's...\n",
    "# Set the working directory to the correct folder\n",
    "os.chdir(\"/Users/sam/Documents/Academics/Data/UdemyDash/\")\n",
    "\n",
    "# Read the CSV with flexible parsing\n",
    "df = pd.read_csv(\"edX_courses_cleaned.csv\", quotechar='\"', on_bad_lines='skip', encoding='utf-8')\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV\n",
    "df.to_csv(\"edX_courses_cleaned_2.csv\", index=False, quoting=1)  # quoting=1 ensures fields with special chars are quoted\n",
    "print(\"Cleaned CSV saved as 'edX_courses_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pushing tables to drive to be visualized in tableau\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "import os\n",
    "\n",
    "# Set the environment variable for authentication\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/sam/Documents/Academics/Data/UdemyDash/planar-effect-452317-h6-597d463b43bb.json\"\n",
    "\n",
    "# Set up your BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Step 2: Query the BigQuery table\n",
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `planar-effect-452317-h6.Udemy_Courses.distinct_subjects`\n",
    "\"\"\"\n",
    "query_job = client.query(query)\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "# Step 3: Export the DataFrame to a CSV file\n",
    "csv_file_path = \"/Users/sam/Documents/Academics/Data/UdemyDash/distinct_subjects.csv\"\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "print(f\"CSV file saved as: {csv_file_path}\")\n",
    "\n",
    "# Step 4: Authenticate and set up Google Drive\n",
    "gauth = GoogleAuth()\n",
    "# This will prompt you to authenticate via browser the first time\n",
    "gauth.LocalWebserverAuth()  # Creates local webserver and auto handles authentication\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Step 5: Upload the CSV file to Google Drive\n",
    "file_title = \"distinct_subjects.csv\"\n",
    "file = drive.CreateFile({'title': file_title})\n",
    "file.SetContentFile(csv_file_path)\n",
    "file.Upload()\n",
    "print(f\"File uploaded to Google Drive with title: {file_title}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
